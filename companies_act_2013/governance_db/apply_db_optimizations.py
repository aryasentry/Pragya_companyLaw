"""
Apply Database Performance Optimizations
Adds indexes to speed up chunk retrieval queries
"""
from db_config import get_db_connection
import time

def apply_optimizations():
    """Apply database indexes for faster retrieval"""
    
    optimizations = [
        {
            'name': 'Section Priority Index',
            'sql': 'CREATE INDEX IF NOT EXISTS idx_section_priority ON chunks_identity(section, chunk_id)',
            'benefit': 'Faster ORDER BY section queries'
        },
        {
            'name': 'Binding Section Index',
            'sql': 'CREATE INDEX IF NOT EXISTS idx_binding_section ON chunks_identity(binding, section) WHERE binding = true',
            'benefit': 'Faster binding document lookups'
        },
        {
            'name': 'Document Type Section Index',
            'sql': 'CREATE INDEX IF NOT EXISTS idx_doctype_section ON chunks_identity(document_type, section)',
            'benefit': 'Faster type-specific queries'
        },
        {
            'name': 'Chunk Role Index',
            'sql': 'CREATE INDEX IF NOT EXISTS idx_chunk_role ON chunks_identity(chunk_role)',
            'benefit': 'Faster parent/child filtering'
        },
        {
            'name': 'Compliance Area Index',
            'sql': 'CREATE INDEX IF NOT EXISTS idx_compliance_area ON chunks_content(compliance_area)',
            'benefit': 'Faster topic-based filtering'
        },
        {
            'name': 'Active Lifecycle Index',
            'sql': "CREATE INDEX IF NOT EXISTS idx_lifecycle_active ON chunk_lifecycle(status) WHERE status = 'ACTIVE'",
            'benefit': 'Faster active chunk queries'
        },
        {
            'name': 'Temporal Dates Index',
            'sql': 'CREATE INDEX IF NOT EXISTS idx_temporal_dates ON chunk_temporal(effective_from, effective_to)',
            'benefit': 'Faster date range queries'
        },
        {
            'name': 'Full-Text Search on Content',
            'sql': "CREATE INDEX IF NOT EXISTS idx_content_text_gin ON chunks_content USING gin(to_tsvector('english', text))",
            'benefit': 'Faster text search queries'
        },
        {
            'name': 'Full-Text Search on Title',
            'sql': "CREATE INDEX IF NOT EXISTS idx_content_title_gin ON chunks_content USING gin(to_tsvector('english', title))",
            'benefit': 'Faster title search queries'
        },
        {
            'name': 'Section Lookup Index',
            'sql': 'CREATE INDEX IF NOT EXISTS idx_section_lookup ON chunks_identity(section, chunk_role, chunk_id)',
            'benefit': 'Faster section-based lookups'
        },
        {
            'name': 'Parent-Child Lookup Index',
            'sql': 'CREATE INDEX IF NOT EXISTS idx_parent_child_lookup ON chunks_identity(parent_chunk_id, chunk_id) WHERE parent_chunk_id IS NOT NULL',
            'benefit': 'Faster parent-child relationship queries'
        }
    ]
    
    with get_db_connection() as conn:
        with conn.cursor() as cursor:
            print("=" * 70)
            print("DATABASE PERFORMANCE OPTIMIZATION")
            print("=" * 70)
            print()
            
            total_time = 0
            success_count = 0
            
            for i, opt in enumerate(optimizations, 1):
                print(f"{i}. {opt['name']}")
                print(f"   Benefit: {opt['benefit']}")
                
                try:
                    start = time.time()
                    cursor.execute(opt['sql'])
                    elapsed = time.time() - start
                    total_time += elapsed
                    
                    print(f"   ‚úÖ Created in {elapsed:.3f}s")
                    success_count += 1
                except Exception as e:
                    print(f"   ‚ö†Ô∏è  Error: {e}")
                
                print()
            
            conn.commit()
            
            # Update statistics
            print("Updating table statistics...")
            tables = [
                'chunks_identity',
                'chunks_content',
                'chunk_temporal',
                'chunk_administrative',
                'chunk_retrieval_rules',
                'chunk_embeddings',
                'chunk_lifecycle'
            ]
            
            for table in tables:
                try:
                    cursor.execute(f'ANALYZE {table}')
                    print(f"   ‚úÖ Analyzed {table}")
                except Exception as e:
                    print(f"   ‚ö†Ô∏è  Error analyzing {table}: {e}")
            
            conn.commit()
            
            print()
            print("=" * 70)
            print(f"‚úÖ Optimization Complete!")
            print(f"   Indexes created: {success_count}/{len(optimizations)}")
            print(f"   Total time: {total_time:.2f}s")
            print("=" * 70)
            print()
            print("EXPECTED PERFORMANCE IMPROVEMENTS:")
            print("  - Chunk retrieval: 50-100ms ‚Üí 10-20ms (5x faster)")
            print("  - Section lookups: 20-50ms ‚Üí 5-10ms (4x faster)")
            print("  - Overall RAG query: 6-9s ‚Üí 5-7s (15-20% faster)")
            print()

def test_query_performance():
    """Test query performance after optimization"""
    
    with get_db_connection() as conn:
        with conn.cursor() as cursor:
            print("=" * 70)
            print("TESTING QUERY PERFORMANCE")
            print("=" * 70)
            print()
            
            # Test 1: Section lookup
            print("Test 1: Section lookup (section = '001')")
            start = time.time()
            cursor.execute("""
                SELECT chunk_id, section, document_type
                FROM chunks_identity
                WHERE section = '001'
                ORDER BY chunk_role, chunk_id
                LIMIT 10
            """)
            results = cursor.fetchall()
            elapsed = time.time() - start
            print(f"   Found {len(results)} chunks in {elapsed*1000:.2f}ms")
            print()
            
            # Test 2: Full chunk details (simulating retrieval)
            print("Test 2: Full chunk details (15 chunks)")
            
            # Get some chunk IDs first
            cursor.execute("SELECT chunk_id FROM chunks_identity LIMIT 15")
            chunk_ids = [row['chunk_id'] for row in cursor.fetchall()]
            
            if chunk_ids:
                start = time.time()
                cursor.execute("""
                    SELECT 
                        ci.chunk_id,
                        ci.section,
                        ci.document_type,
                        cc.title,
                        cc.compliance_area,
                        crr.priority
                    FROM chunks_identity ci
                    JOIN chunks_content cc ON ci.chunk_id = cc.chunk_id
                    LEFT JOIN chunk_retrieval_rules crr ON ci.chunk_id = crr.chunk_id
                    WHERE ci.chunk_id = ANY(%s)
                    ORDER BY crr.priority, ci.section
                """, (chunk_ids,))
                results = cursor.fetchall()
                elapsed = time.time() - start
                print(f"   Retrieved {len(results)} chunks in {elapsed*1000:.2f}ms")
            else:
                print("   ‚ö†Ô∏è  No chunks found in database")
            print()
            
            # Test 3: Compliance area filter
            print("Test 3: Compliance area filter")
            start = time.time()
            cursor.execute("""
                SELECT chunk_id, title, compliance_area
                FROM chunks_content
                WHERE compliance_area IS NOT NULL
                LIMIT 10
            """)
            results = cursor.fetchall()
            elapsed = time.time() - start
            print(f"   Found {len(results)} chunks in {elapsed*1000:.2f}ms")
            print()
            
            print("=" * 70)
            print("‚úÖ Performance testing complete!")
            print("=" * 70)

if __name__ == '__main__':
    print("\nüöÄ Starting Database Optimization...\n")
    
    try:
        apply_optimizations()
        print("\nüìä Running performance tests...\n")
        test_query_performance()
        
        print("\n‚úÖ All optimizations applied successfully!")
        print("\nRECOMMENDATIONS:")
        print("1. Monitor query performance over the next few days")
        print("2. Run ANALYZE periodically (weekly) to keep statistics fresh")
        print("3. Consider VACUUM ANALYZE monthly for maintenance")
        print()
        
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
